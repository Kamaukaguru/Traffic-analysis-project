{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9XQ0B6NfktMB"
   },
   "source": [
    "# TRAFFIC ANALYSIS PROJECT\n",
    "## BY: Group 5\n",
    "1. Kevin Muchori\n",
    "2. Benson Kamau\n",
    "3. Sally Kinyanjui\n",
    "4. Breden Mugambi\n",
    "5. Nancy Chelangat\n",
    "\n",
    "## Overview:  \n",
    "The urban mobility and transportation sector are vital for the functioning of modern cities, enabling the movement of people and goods efficiently. Within this industry, traffic management and pedestrian safety are crucial components that directly impact the quality of life in urban areas. Effective traffic pattern analysis and prediction can help mitigate congestion, enhance safety, and improve overall urban mobility.\n",
    "Well managed traffic leads to minimized economic losses, improved quality of life especially on the side of pedestrians.\n",
    "\n",
    "## Challenges:\n",
    "There are so many problems that are encountered especially in most urban towns whose vehicle and pedestrian population continues to grow every day. One of the problems is the traffic congestion which leads to higher traffic volumes which in turn brings about economic losses due to wasted time and fuel, increased pollution. Another key challenge is the pedestrian safety where High pedestrian traffic in urban areas increases the risk of accidents.  A challenge to also note is collecting accurate and real-time data from various sources is challenging which would make accurate traffic and pedestrian predictions challenging.\n",
    "\n",
    "## Proposed solutions:\n",
    "To solve some of these challenges would include measures such as advocating for sustainable urban mobility policies and invest in supportive infrastructure.  Use of Use machine learning models to analyze and predict traffic patterns and pedestrian crossings at different times of the day. In order to gather real-time data on traffic and pedestrian movement would require use of high technology like IoT devices.\n",
    "\n",
    "## Conclusion:\n",
    "The analysis and prediction of traffic congestion levels and pedestrian crossings are essential for enhancing urban mobility and safety. Successful implementation of these solutions can lead to reduced congestion, fewer accidents, and an overall improvement in the quality of urban life.\n",
    "\n",
    "\n",
    "## Problem Statement:\n",
    "\n",
    "Urban areas continue to face significant challenges in managing their traffic congestion and ensuring pedestrian safety. The changing nature of these areas together with the increasing volume of both vehicle and pedestrian traffic, makes it hard for one to predict traffic patterns affectively.\n",
    "\n",
    "## Objective :\n",
    "Our primary objective is to create an accurate time series model(s) that can model, analyze and predict traffic congestion levels and pedestrian crossings at different times of the day.\n",
    "\n",
    "### Specific objectives:\n",
    "1.  To identify key factors that influence traffic and pedestrian movement\n",
    "2.  To develop predictive models for forecasting future traffic congestion and pedestrian crossing patterns.\n",
    "3.  To provide recommendations for urban planners and traffic management authorities to improve traffic flow and pedestrian safety.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1x_BabTrktMG"
   },
   "source": [
    "## Data Understanding\n",
    "The data to use in this study is sourced from the UC Irvine Machine Learning Repository.  It has 4760 rows and 14 data features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7oewEnIFktMG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "W3W68l1Hk4-O"
   },
   "outputs": [],
   "source": [
    "#create a function that loads data and gets the info about the data.\n",
    "def load_and_get_info(file_path, encoding='utf-8'):\n",
    "    try :\n",
    "        # Load data\n",
    "        df = pd.read_csv(file_path, encoding=encoding)\n",
    "\n",
    "        # Display the first few rows of the DataFrame\n",
    "        df_head = df.head()\n",
    "\n",
    "        # Get information about the DataFrame\n",
    "        df_info = df.info()\n",
    "\n",
    "        return df,df_info, df_head\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Failed to decode {file_path} with encoding {encoding}. Trying with 'latin1' encoding.\")\n",
    "        return load_and_get_info(file_path, encoding='latin1')\n",
    "\n",
    "# A function that checks the data types of DataFrame columns and return the count of columns for each data type category.\n",
    "def check_data_types(df):\n",
    "\n",
    "    data_type_counts = df.dtypes.replace({'object': 'string'}).value_counts().to_dict()\n",
    "    return data_type_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Cvs2NxCaliHU",
    "outputId": "1ff235b4-660b-4fd0-c3cb-fcaf3875b106"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/traffic_data1 (1).csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/traffic_data1 (1).csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#file_path = '/Users/mac/Documents/GitHub/Traffic-analysis-project/traffic_data1 (1).csv'\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df1,data_info, data_head \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_get_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(data_info)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFirst few rows of the DataFrame:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m, in \u001b[0;36mload_and_get_info\u001b[0;34m(file_path, encoding)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_and_get_info\u001b[39m(file_path, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m :\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m         df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;66;03m# Display the first few rows of the DataFrame\u001b[39;00m\n\u001b[1;32m      8\u001b[0m         df_head \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/learn-env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/learn-env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/learn-env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/learn-env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/learn-env/lib/python3.9/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/traffic_data1 (1).csv'"
     ]
    }
   ],
   "source": [
    "file_path = '/content/traffic_data1 (1).csv'\n",
    "#file_path = '/Users/mac/Documents/GitHub/Traffic-analysis-project/traffic_data1 (1).csv'\n",
    "df1,data_info, data_head = load_and_get_info(file_path)\n",
    "print(data_info)\n",
    "print(\"\\nFirst few rows of the DataFrame:\")\n",
    "data_head #data_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rkUJwJkKmBgi"
   },
   "source": [
    "The dataset contains the following columns:\n",
    "\n",
    "oid: This column represents a unique identifier for each object record in the dataset.\n",
    "\n",
    "timestamp: This column stores the exact time of each record\n",
    "\n",
    "date: This column extracts the date portion from the timestamp column, providing the day without the time information.\n",
    "\n",
    "hour: This column extracts the hour of the day (0-23) from the 'timestamp' column.\n",
    "\n",
    "x: This column represents the X-coordinate of each object in our data.\n",
    "\n",
    "y: This column represents the Y-coordinate of each object in our data.\n",
    "\n",
    "vehicle_count: This column indicates the number of vehicles observed in the vicinity of each object record.\n",
    "\n",
    "pedestrian_count: This column reflects the number of pedestrians observed in the vicinity of each object record.\n",
    "\n",
    "congestion_level: This column categorizes the traffic congestion level at the time of each record.\n",
    "\n",
    "weather_condition: This column represents the weather condition at the time of each record\n",
    "\n",
    "temperature: This column holds the temperature recorded at the time of each data point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYnYBsqwmkAC"
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LjBEsNLbmmyY"
   },
   "source": [
    "### Step 1: Dropping  the empty columns\n",
    "\n",
    "The columns body_roll, body_pitch, body_yaw, head_roll, head_pitch, and head_yaw have no data therefore will not be useful for our project. We will therefore proceed to drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9lL-LmMAoyvl"
   },
   "outputs": [],
   "source": [
    "columns_to_drop = ['body_roll', 'body_pitch', 'body_yaw', 'head_roll', 'head_pitch', 'head_yaw']\n",
    "cleaned_df = df1.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Q0cf1K5r8H-"
   },
   "source": [
    "Step 2: Convert the 'timestamp' column to datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M2Vpo2Skr8ad"
   },
   "outputs": [],
   "source": [
    "cleaned_df['date'] = pd.to_datetime(cleaned_df['date'])\n",
    "cleaned_df['timestamp'] = pd.to_datetime(cleaned_df['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLcwISUov9Gg"
   },
   "source": [
    "### Step 3: Check for and remove duplicate rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "id": "EhkuxjX0v8C2",
    "outputId": "d267dfbd-e064-4fba-ab7a-f4b75b3d4d36"
   },
   "outputs": [],
   "source": [
    "cleaned_df = cleaned_df.drop_duplicates()\n",
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dh7v_Sktgvw"
   },
   "source": [
    "Below we will go ahead and breakdown timestamps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-J2cZihWtgvw"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Extract date components\n",
    "cleaned_df['year'] = cleaned_df['timestamp'].dt.year\n",
    "cleaned_df['month'] = cleaned_df['timestamp'].dt.month\n",
    "\n",
    "# Create time-based features\n",
    "cleaned_df['day_of_week'] = cleaned_df['timestamp'].dt.dayofweek\n",
    "cleaned_df['hour'] = cleaned_df['timestamp'].dt.hour\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TBhNlTAtgvx"
   },
   "source": [
    "By breaking down our project into components, we can be able to use our data in more useful ways for example:\n",
    "- Comapring traffic levels between weekdays and weekends\n",
    "- Identifying patterns in traffic congestion at different times of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 834
    },
    "id": "eh3CyAKstgvx",
    "outputId": "77068c26-b276-48f6-db3e-0c810f66ce5d"
   },
   "outputs": [],
   "source": [
    "cleaned_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYQgYKDFtgvx"
   },
   "source": [
    "From the output,we see that we now have columns indicating the year, month and day of the week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rvxNKiY-tgvy"
   },
   "source": [
    "Let us see whether it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "RiTAAs_ytgvy",
    "outputId": "77ab2d45-3d4a-4f99-df22-f3195dd688f0"
   },
   "outputs": [],
   "source": [
    "\"\"\"import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'timestamp': ['2023-01-15', '2023-02-10', '2023-01-25', '2023-03-05'],\n",
    "        'value': [10, 20, 15, 25]}\n",
    "df = pd.DataFrame(data)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['month'] = df['timestamp'].dt.month\n",
    "\n",
    "# Filter for January data\n",
    "january_data = df[df['month'] == 1]\n",
    "\n",
    "print(january_data)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7iMjCGVtgvy"
   },
   "source": [
    "From the output we can see that the from the sample dataframe we had provided,the following timestamps are the ones that belong to the month of January."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ocs0PEf4tgvz",
    "outputId": "f5ef4b1a-c269-4b4f-dff0-8fe264e611b2"
   },
   "outputs": [],
   "source": [
    "cleaned_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jY0MI9kg5qg0"
   },
   "source": [
    "# **EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ei2nUMof2h4a",
    "outputId": "e744f559-09f2-4e72-dc9f-46189b11fcd8"
   },
   "outputs": [],
   "source": [
    "df = cleaned_df\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPt5ErYhx6NH"
   },
   "source": [
    "Checking the values in the different columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KOpSFldOyNXJ"
   },
   "source": [
    "Plotting\n",
    "create a function that will be used to plot histograms to show frequency in the different applicable columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R1DJ1AxpwCA5"
   },
   "outputs": [],
   "source": [
    "def frequency_plotting(df, column_name):\n",
    "    \"\"\"\n",
    "    Plots a bar graph of the frequency distribution for a given column in a DataFrame,\n",
    "    with values displayed on top of each bar.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame containing the data.\n",
    "        column_name (str): The name of the column to plot the frequency distribution for.\n",
    "    \"\"\"\n",
    "\n",
    "    # Print value counts for reference\n",
    "    print(df[column_name].value_counts())\n",
    "\n",
    "    # Get values and counts\n",
    "    x_values = df[column_name].value_counts().index\n",
    "    y_values = df[column_name].value_counts().values\n",
    "\n",
    "    # Create the bar graph\n",
    "    plt.figure(figsize=(8, 6))  # Set a reasonable figure size\n",
    "    bars = plt.bar(x_values, y_values, edgecolor='black')\n",
    "\n",
    "\n",
    "\n",
    "    for bar, value in zip(bars, y_values):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), value,\n",
    "                 ha='center', va='bottom')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel(column_name)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Distribution of {column_name}')\n",
    "    plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for readability\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 711
    },
    "id": "zQMxdY08zw0c",
    "outputId": "2cedb70a-8a59-4fd4-d208-f97e76d6a016"
   },
   "outputs": [],
   "source": [
    "frequency_plotting(df, 'weather_condition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 694
    },
    "id": "BFMm8cB0z0IR",
    "outputId": "12db4645-4663-4b8e-e6df-85ea4aeca530"
   },
   "outputs": [],
   "source": [
    "frequency_plotting(df, 'congestion_level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "id": "fAG7K1-70dMQ",
    "outputId": "a5757279-886c-48d9-d5cf-7864d4bef899"
   },
   "outputs": [],
   "source": [
    "frequency_plotting(df, 'temperature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgfe5EA_4tdZ"
   },
   "source": [
    "temp and time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 989
    },
    "id": "XXHIi9hO0mq-",
    "outputId": "e055dc80-5e7c-408a-914c-9cc641129f26"
   },
   "outputs": [],
   "source": [
    "frequency_plotting(df, 'vehicle_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FSj8FWi_4yYS",
    "outputId": "fa912349-5c9c-4e33-e69c-21f2f9e13d44"
   },
   "outputs": [],
   "source": [
    "frequency_plotting(df, 'pedestrian_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary libraries for modelimg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.tsa.stattools as sm\n",
    "import statsmodels.tsa.arima_model as ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from pandas import tseries\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
